{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"dataset\" # dir where your train/dev.in is stored\n",
    "FEATURE_OUTPUT_DIRECTORY = \"features\"\n",
    "LEARN_CO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('./dataset/test.in', 'r', encoding='utf-8') as a:\n",
    "    sents = a.read()\n",
    "    sents = sents.replace(\"\\n\\n\", \"\\n\")\n",
    "with open('./dataset/test2.in', 'w', encoding='utf-8') as test2:\n",
    "    test2.write(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_file(directory):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    all_tags = []\n",
    "    all_words = []\n",
    "\n",
    "    with open(directory) as f:\n",
    "        x_sent = []\n",
    "        y = []\n",
    "        for line in f:\n",
    "            if line == '\\n': # end of a sentence\n",
    "                x_train.append(x_sent)\n",
    "                y_train.append(y)\n",
    "                x_sent=[]\n",
    "                y=[]\n",
    "            else:\n",
    "                temp = line.strip().split()\n",
    "                x_sent.append(temp[0]) # word\n",
    "                y.append(temp[1]) # tag\n",
    "\n",
    "                if temp[1] not in all_tags:\n",
    "                    all_tags.append(temp[1])\n",
    "                if temp[0] not in all_words:\n",
    "                    all_words.append(temp[0])\n",
    "\n",
    "    return x_train, y_train, all_tags, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, ALL_TAGS,  ALL_WORDS = read_train_file(DATA_FILE + '/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_feature(feat, output_file):\n",
    "    with open(output_file, \"w\") as out:\n",
    "        for (k, v) in feat.items():\n",
    "            out.write(f\"{k} {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict(x_train, y_train, output_dir):\n",
    "    \n",
    "    features = {}\n",
    "    tags = ALL_TAGS + [\"START\", \"STOP\"]\n",
    "    \n",
    "    for i in tags:\n",
    "        for j in tags:\n",
    "            string = f\"transition:{str(i)}+{str(j)}\"\n",
    "            features[string] = -2**21\n",
    "            \n",
    "    for j in ALL_TAGS:\n",
    "        for i in ALL_WORDS:\n",
    "            string = f\"emission:{str(j)}+{str(i)}\"\n",
    "            features[string] = -2**21\n",
    "            \n",
    "    label_dict = defaultdict(int)  # {LABEL : COUNT} e.g: {'o': 24273, 'B-negative': 278, ...}\n",
    "    word_label_dict = defaultdict(int) # {(LABEL, WORD): COUNT} \n",
    "                               # e.g: {('O', 'All'): 3, ('B-positive', 'food'): 131, ...}\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(len(x_train[i])):\n",
    "            label_dict[y_train[i][j]] += 1\n",
    "            word_label_dict[(y_train[i][j], x_train[i][j])] += 1\n",
    "    \n",
    "    # print(f\"y_dict: {y_dict}\")\n",
    "    # print(f\"yx_dict: {yx_dict}\")\n",
    "\n",
    "    emission = defaultdict(int)\n",
    "    for k in word_label_dict:\n",
    "        tag = k[0]\n",
    "        string = f\"emission:{str(k[0])}+{str(k[1])}\"\n",
    "        emission[string] = math.log(float(word_label_dict[k])/label_dict[tag])\n",
    "    # print(f\"emission: {emission}\")\n",
    "\n",
    "    # getting transition\n",
    "    yi_dict = defaultdict(int)\n",
    "    yj_dict = defaultdict(int)\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "#         if len(y_train[i]) == 0: # this seems to be useless\n",
    "#             continue\n",
    "\n",
    "         # adding START and STOP tag to each sentence\n",
    "        yi_dict['START'] += 1\n",
    "        yj_dict[('START', y_train[i][0])] += 1\n",
    "        yj_dict[(y_train[i][-1],'STOP')] += 1\n",
    "\n",
    "        for j in range(len(x_train[i])-1):\n",
    "            yi_dict[y_train[i][j]] += 1\n",
    "            yj_dict[(y_train[i][j],y_train[i][j+1])] += 1\n",
    "        yi_dict[y_train[i][-1]] += 1\n",
    "                \n",
    "    transition = defaultdict(int)\n",
    "    for k in yj_dict:\n",
    "        string = f\"transition:{str(k[0])}+{str(k[1])}\"\n",
    "        transition[string] = math.log(float(yj_dict[k])/yi_dict[k[0]])\n",
    "    \n",
    "    if \"transition:START+STOP\" in transition:\n",
    "        del transition[\"transition:START+STOP\"]\n",
    "\n",
    "    write_feature(emission, output_dir + \"/emission_P1.txt\") # save emission dictionary\n",
    "    write_feature(transition, output_dir + \"/transition_P1.txt\") # save transition dictionary\n",
    "\n",
    "    for key in emission:\n",
    "        features[key] = emission[key]\n",
    "    for key in transition:\n",
    "        features[key] = transition[key]\n",
    "\n",
    "    return features, emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict, emission = get_feature_dict(x_train, y_train, FEATURE_OUTPUT_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states():   \n",
    "    sents = []\n",
    "    sents.append('START')\n",
    "    with open('./dataset/train', 'r', encoding='utf-8') as trainfile:\n",
    "        lines = trainfile.readlines()\n",
    "        for line in lines:\n",
    "            x = line.split(' ')\n",
    "            # print(x)\n",
    "            if len(x) != 1: #for \\n\n",
    "                sents.append(x)\n",
    "            else:\n",
    "                sents.append('STOP')\n",
    "                sents.append('START')\n",
    "        # print(sents)\n",
    "\n",
    "    states = []\n",
    "    for term in range(len(sents) - 1):\n",
    "        if len(sents[term]) == 2:\n",
    "            states.append(sents[term][1].rstrip()) #append the word\n",
    "        else:\n",
    "            states.append(sents[term].rstrip()) #append start/stop\n",
    "    return states\n",
    "\n",
    "def get_bigram_count(states):\n",
    "    bigram_count = dict()\n",
    "    for i in range(len(states)-1):\n",
    "        if(states[i+1]=='START'):\n",
    "            continue\n",
    "        bigram_count[f'transition:{states[i]}+{states[i+1]}'] = bigram_count.get('transition:'+states[i]+ '+'+states[i+1], 0) + 1 \n",
    "    start_stop = dict()\n",
    "    for i in range(len(states)):\n",
    "        start_stop[states[i]] = start_stop.get(states[i], 0) + 1 \n",
    "    return bigram_count, start_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigram_count(states):\n",
    "    trigram_count = dict()\n",
    "    for i in range(1,len(states)-1):\n",
    "        if(states[i+1]=='START' or states[i-1] == 'STOP'):\n",
    "            continue #skip to next \n",
    "        trigram_count[f'transition:{states[i-1]}+{states[i]}+{states[i+1]}'] = trigram_count.get(f'transition:{states[i-1]}+{states[i]}+{states[i+1]}', 0) + 1 \n",
    "\n",
    "    return trigram_count\n",
    "\n",
    "def get_bi_trans(y, y1, bi_dict, label_dict):\n",
    "    if f'transition:{y}+{y1}' not in bi_dict:\n",
    "        return 0.0\n",
    "    bigram_count = bi_dict[f'transition:{y}+{y1}']\n",
    "    count_y = label_dict[y]\n",
    "    bi_trans = bigram_count/count_y\n",
    "    return bi_trans\n",
    "\n",
    "def get_bi_trans_dict(emission_dict, bigram_count, label_dict, states):\n",
    "    for i in range(len(states)-1):\n",
    "        if (states[i+1]=='START'):\n",
    "            continue\n",
    "        emission_dict['transition:'+states[i]+'+'+states[i+1]] = math.log(get_bi_trans(states[i], states[i+1], bigram_count, label_dict))\n",
    "    return emission_dict\n",
    "\n",
    "def get_tri_trans(y, y1, y2, trigram_dict, bigram_dict):\n",
    "    if f'transition:{y}+{y1}+{y2}' not in trigram_dict:\n",
    "        return 0.0\n",
    "    count_trigram = trigram_dict[f'transition:{y}+{y1}+{y2}']\n",
    "    count_u_v = bigram_dict[f\"transition:{y}+{y1}\"]\n",
    "    result = count_trigram / count_u_v\n",
    "    return result\n",
    "\n",
    "def get_tri_trans_dict(emission_dict, trigram, bigram, states):\n",
    "    for i in range(1,len(states)-1):\n",
    "        if (states[i+1]=='START' or states[i-1]==\"STOP\"):\n",
    "            continue\n",
    "        emission_dict[f'transition:{states[i-1]}+{states[i]}+{states[i+1]}'] = math.log(get_tri_trans(states[i-1],states[i],states[i+1],trigram,bigram))\n",
    "    return emission_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_states = get_states()\n",
    "bigram_count, start_stop = get_bigram_count(data_states)\n",
    "x_train, y_train, all_tags, all_words = read_train_file('./dataset/train')\n",
    "bigram_dict = get_bi_trans_dict(emission, bigram_count, start_stop, data_states)\n",
    "trigram_count = get_trigram_count(data_states)\n",
    "trigram_dict = get_tri_trans_dict(emission,trigram_count , bigram_count, data_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_p6(x, states, trigram_dict):\n",
    "    scores = np.full((len(x), len(states)), -np.inf)\n",
    "    parents = np.full((len(x), len(states)), 0, dtype=int)\n",
    "    \n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(states)):\n",
    "            emission_key1 = f\"emission:{states[i]}+{x[0]}\"\n",
    "            transition_key = f\"transition:start+{states[i]}\"\n",
    "            trigram_key = f\"transition:start+{states[i]}+{states[j]}\"\n",
    "            scores[0, i] = trigram_dict.get(emission_key1, -10e8) + trigram_dict.get(trigram_key, -10e8) + trigram_dict.get(transition_key, -10e8)\n",
    "    \n",
    "    for i in range(1, len(x)):\n",
    "        for j in range(len(states)):\n",
    "            for tri in range(len(states)):\n",
    "                for k in range(len(states)):\n",
    "                    emission_key1 = f\"emission:{states[k]}+{x[i].split()[0]}\"\n",
    "                    trigram_key = f\"transition:{states[j]}+{states[tri]}+{states[k]}\"\n",
    "                    transition_key = f\"transition:{states[j]}+{states[k]}\"\n",
    "                    overall_score = scores[i-1, j] + trigram_dict.get(emission_key1, -10e8) + trigram_dict.get(trigram_key, -10e8) + trigram_dict.get(transition_key, -10e8)\n",
    "\n",
    "                    if overall_score > scores[i, k]:\n",
    "                        scores[i, k] = overall_score\n",
    "                        parents[i,k] = j\n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_parent = None\n",
    "    \n",
    "    for i in range(len(states)):\n",
    "        for j in range(len(states)):\n",
    "            t_feature = f\"transition:{states[i]}+stop\"\n",
    "            trigram_feature = f\"transition:{states[i]}+{states[j]}+stop\"\n",
    "            total = scores[len(x)-1, i] + trigram_dict.get(t_feature, -10**8) + trigram_dict.get(trigram_feature,-10**8)\n",
    "            if total > best_score:\n",
    "                best_score = total\n",
    "                best_parent = i\n",
    "    best_state = [states[best_parent]]\n",
    "    prev_parent = best_parent\n",
    "    for i in range(len(x)-1, 0, -1):\n",
    "        prev_parent = parents[i, prev_parent]\n",
    "        output = states[prev_parent]\n",
    "        best_state = [output] + best_state\n",
    "    return best_state\n",
    "states = list(set(all_tags))\n",
    "\n",
    "def get_prediction(resulting_dict):\n",
    "    with open('./dataset/test2.in', 'r', encoding=\"utf-8\") as test_set:\n",
    "        lines = test_set.readlines()\n",
    "    sequences = []\n",
    "    sequence = []\n",
    "    for line in lines:\n",
    "        if line == '\\n':\n",
    "            sequences.append(sequence)\n",
    "            sequence = []\n",
    "            continue\n",
    "\n",
    "        line = line.replace('\\n', '')\n",
    "        sequence.append(line)\n",
    "    \n",
    "    with open('./features/test.p6.CRF.out', \"w\", encoding=\"utf-8\") as out_file:\n",
    "        # print(resulting_dict)\n",
    "        for x in sequences:\n",
    "            predicted= viterbi_p6(x, states, resulting_dict)\n",
    "            # predicted = predicted[1:-1]\n",
    "            for i in range(len(x)):\n",
    "                out_file.write(x[i] + ' ' + predicted[i] + '\\n')\n",
    "            out_file.write('\\n')\n",
    "        out_file.close()\n",
    "get_prediction(trigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
