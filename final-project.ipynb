{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b341762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d6f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"dataset\" # dir where your train/dev.in is stored\n",
    "FEATURE_OUTPUT_DIRECTORY = \"features\"\n",
    "LEARN_CO = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5c369",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dfd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_file(directory):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    all_tags = []\n",
    "    all_words = []\n",
    "\n",
    "    with open(directory) as f:\n",
    "        x_sent = []\n",
    "        y = []\n",
    "        for line in f:\n",
    "            if line == '\\n': # end of a sentence\n",
    "                x_train.append(x_sent)\n",
    "                y_train.append(y)\n",
    "                x_sent=[]\n",
    "                y=[]\n",
    "            else:\n",
    "                temp = line.strip().split()\n",
    "                x_sent.append(temp[0]) # word\n",
    "                y.append(temp[1]) # tag\n",
    "\n",
    "                if temp[1] not in all_tags:\n",
    "                    all_tags.append(temp[1])\n",
    "                if temp[0] not in all_words:\n",
    "                    all_words.append(temp[0])\n",
    "\n",
    "    return x_train, y_train, all_tags, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105968f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_validation_file(directory):\n",
    "    dev = []\n",
    "    with open(directory) as f:\n",
    "        s = []\n",
    "        for line in f:\n",
    "            if line == '\\n':\n",
    "                dev.append(s)\n",
    "                s = []\n",
    "            else:\n",
    "                temp = line.strip()\n",
    "                s.append(temp)\n",
    "    return dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4885f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, ALL_TAGS,  ALL_WORDS = read_train_file(DATA_FILE + '/train')\n",
    "all_tags_len = len(ALL_TAGS)\n",
    "# x_train\n",
    "# ALL_TAGS # without START, STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27af118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_feature(feat, output_file):\n",
    "    with open(output_file, \"w\") as out:\n",
    "        for (k, v) in feat.items():\n",
    "            out.write(f\"{k} {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d24349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict(x_train, y_train, output_dir):\n",
    "    \n",
    "    features = {}\n",
    "    tags = ALL_TAGS + [\"START\", \"STOP\"]\n",
    "    \n",
    "    for i in tags:\n",
    "        for j in tags:\n",
    "            string = f\"transition:{str(i)}+{str(j)}\"\n",
    "            features[string] = -2**21\n",
    "            \n",
    "    for j in ALL_TAGS:\n",
    "        for i in ALL_WORDS:\n",
    "            string = f\"emission:{str(j)}+{str(i)}\"\n",
    "            features[string] = -2**21\n",
    "            \n",
    "    label_dict = defaultdict(int)  # {LABEL : COUNT} e.g: {'o': 24273, 'B-negative': 278, ...}\n",
    "    word_label_dict = defaultdict(int) # {(LABEL, WORD): COUNT} \n",
    "                               # e.g: {('O', 'All'): 3, ('B-positive', 'food'): 131, ...}\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(len(x_train[i])):\n",
    "            label_dict[y_train[i][j]] += 1\n",
    "            word_label_dict[(y_train[i][j], x_train[i][j])] += 1\n",
    "    \n",
    "    # print(f\"y_dict: {y_dict}\")\n",
    "    # print(f\"yx_dict: {yx_dict}\")\n",
    "\n",
    "    emission = defaultdict(int)\n",
    "    for k in word_label_dict:\n",
    "        tag = k[0]\n",
    "        string = f\"emission:{str(k[0])}+{str(k[1])}\"\n",
    "        emission[string] = math.log(float(word_label_dict[k])/label_dict[tag])\n",
    "    # print(f\"emission: {emission}\")\n",
    "\n",
    "    # getting transition\n",
    "    yi_dict = defaultdict(int)\n",
    "    yj_dict = defaultdict(int)\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "#         if len(y_train[i]) == 0: # this seems to be useless\n",
    "#             continue\n",
    "\n",
    "         # adding START and STOP tag to each sentence\n",
    "        yi_dict['START'] += 1\n",
    "        yj_dict[('START', y_train[i][0])] += 1\n",
    "        yj_dict[(y_train[i][-1],'STOP')] += 1\n",
    "\n",
    "        for j in range(len(x_train[i])-1):\n",
    "            yi_dict[y_train[i][j]] += 1\n",
    "            yj_dict[(y_train[i][j],y_train[i][j+1])] += 1\n",
    "        yi_dict[y_train[i][-1]] += 1\n",
    "                \n",
    "    transition = defaultdict(int)\n",
    "    for k in yj_dict:\n",
    "        string = f\"transition:{str(k[0])}+{str(k[1])}\"\n",
    "        transition[string] = math.log(float(yj_dict[k])/yi_dict[k[0]])\n",
    "    \n",
    "    if \"transition:START+STOP\" in transition:\n",
    "        del transition[\"transition:START+STOP\"]\n",
    "\n",
    "    write_feature(emission, output_dir + \"/emission_P1.txt\") # save emission dictionary\n",
    "    write_feature(transition, output_dir + \"/transition_P1.txt\") # save transition dictionary\n",
    "\n",
    "    for key in emission:\n",
    "        features[key] = emission[key]\n",
    "    for key in transition:\n",
    "        features[key] = transition[key]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5d462ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = get_feature_dict(x_train, y_train, FEATURE_OUTPUT_DIRECTORY)\n",
    "write_feature(feature_dict, FEATURE_OUTPUT_DIRECTORY + \"/features_P1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca621c5",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0b3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sent, feature_dict): \n",
    "    table = []\n",
    "    for i in range(all_tags_len):\n",
    "        temp = []\n",
    "        for j in range(len(sent)):\n",
    "            temp.append(-2**31)\n",
    "        table.append(temp)\n",
    "            \n",
    "    trace = []\n",
    "    for j in range(all_tags_len):\n",
    "        temp = []\n",
    "        for i in range(len(sent)):\n",
    "            temp.append(None)\n",
    "        trace.append(temp)\n",
    "    \n",
    "    score = -2**31\n",
    "    pointer = None\n",
    "    \n",
    "    # START -> first tag\n",
    "    # check first word sent[0]\n",
    "    for i in range(all_tags_len):\n",
    "        trace[i][0] = 'START'\n",
    "        if (f\"emission:{ALL_TAGS[i]}+{sent[0]}\" in feature_dict):\n",
    "            table[i][0] = feature_dict[f\"transition:START+{ALL_TAGS[i]}\"] +\\\n",
    "                          feature_dict[f\"emission:{ALL_TAGS[i]}+{sent[0]}\"]\n",
    "        else:\n",
    "            table[i][0] = feature_dict[f\"transition:START+{ALL_TAGS[i]}\"]\n",
    "          \n",
    "            \n",
    "            \n",
    "    # iterate through the rest of sent\n",
    "    for s in range(1, len(sent)):\n",
    "        for v in range(all_tags_len):\n",
    "            \n",
    "            # transition score u -> v\n",
    "            for u in range(all_tags_len):\n",
    "                if table[v][s] < table[u][s-1] + feature_dict[f\"transition:{ALL_TAGS[u]}+{ALL_TAGS[v]}\"]:\n",
    "                    table[v][s] = table[u][s-1] + feature_dict[f\"transition:{ALL_TAGS[u]}+{ALL_TAGS[v]}\"]\n",
    "                    trace[v][s] = u\n",
    "                    \n",
    "            if (f\"emission:{ALL_TAGS[v]}+{sent[s]}\" in feature_dict):\n",
    "                table[v][s] += feature_dict[f\"emission:{ALL_TAGS[v]}+{sent[s]}\"]\n",
    "\n",
    "                \n",
    "    # last word -> STOP\n",
    "    for i in range(all_tags_len):\n",
    "        if score < table[i][-1] + feature_dict[f\"transition:{ALL_TAGS[i]}+STOP\"]:\n",
    "            score = table[i][-1] + feature_dict[f\"transition:{ALL_TAGS[i]}+STOP\"]\n",
    "            pointer = i\n",
    "    \n",
    "    output = ['STOP']\n",
    "    output.append(ALL_TAGS[pointer])\n",
    "    wanted_tag = pointer\n",
    "\n",
    "    for i in range(len(sent)-1, 0, -1):\n",
    "        output.append(ALL_TAGS[trace[wanted_tag][i]])\n",
    "        wanted_tag = trace[wanted_tag][i]\n",
    "    \n",
    "    output.append('START')\n",
    "    return output[::-1], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3369cb28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['START', 'O', 'B-positive', 'O', 'O', 'O', 'B-positive', 'O', 'STOP'],\n",
       " -46.66025618822654)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi('Great food with an awesome atmosphere !'.split(), feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28780ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(directory, x, y):\n",
    "    with open(directory, 'w') as f:\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x[i])):\n",
    "                f.write(f\"{x[i][j]} {y[i][j]}\\n\")\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3768f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = read_validation_file(DATA_FILE +'/dev.in')\n",
    "y_dev = []\n",
    "\n",
    "for i in range(len(x_dev)):\n",
    "    output,_ = viterbi(x_dev[i], feature_dict)\n",
    "    y_dev.append(output[1:-1]) #remove START, STOP\n",
    "\n",
    "write_output(DATA_FILE +'/dev.p2.out', x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c8524",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2235057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(n):\n",
    "    _max = np.max(n)\n",
    "    i = n - _max\n",
    "    _sum = np.exp(i).sum()\n",
    "    return np.log(_sum) + _max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29bd9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(sent, feature_dict):\n",
    "    alpha = []\n",
    "    for j in range(all_tags_len):\n",
    "        temp = []\n",
    "        for i in range(len(sent)):\n",
    "            temp.append(0)\n",
    "        alpha.append(temp)\n",
    "    \n",
    "    # START -> first tag\n",
    "    # check first word sent[0]\n",
    "    for i in range(all_tags_len):\n",
    "        alpha[i][0] = feature_dict[f\"transition:START+{ALL_TAGS[i]}\"] +\\\n",
    "                      feature_dict[f\"emission:{ALL_TAGS[i]}+{sent[0]}\"]\n",
    "        \n",
    "    # iterate through the rest of sent\n",
    "    for i in range(1, len(sent)):\n",
    "        for v in range(all_tags_len):\n",
    "            temp = np.zeros(all_tags_len)\n",
    "            \n",
    "            # transition score u -> v\n",
    "            for u in range(all_tags_len):\n",
    "                temp[u] = alpha[u][i-1] +\\\n",
    "                           feature_dict[f\"transition:{ALL_TAGS[u]}+{ALL_TAGS[v]}\"] +\\\n",
    "                           feature_dict[f\"emission:{ALL_TAGS[v]}+{sent[i]}\"]\n",
    "            alpha[v][i] = log_sum_exp(temp)\n",
    "    \n",
    "    # last word -> STOP\n",
    "    temp = np.zeros(all_tags_len)\n",
    "    for i in range(all_tags_len):\n",
    "        temp[i] = alpha[i][-1] + feature_dict[f\"transition:{ALL_TAGS[i]}+STOP\"]\n",
    "    \n",
    "    return alpha, log_sum_exp(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89b304be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(sent, feature_dict):\n",
    "    beta = []\n",
    "    for i in range(all_tags_len):\n",
    "        temp = []\n",
    "        for j in range(len(sent)):\n",
    "            temp.append(0)\n",
    "        beta.append(temp)\n",
    "    \n",
    "    for i in range(all_tags_len):\n",
    "        beta[i][-1] = feature_dict[f\"transition:{ALL_TAGS[i]}+STOP\"]\n",
    "    \n",
    "    for i in range(len(sent)-2, -1, -1):\n",
    "        for v in range(all_tags_len):\n",
    "            temp = np.zeros(all_tags_len)\n",
    "            \n",
    "            for u in range(all_tags_len):\n",
    "                temp[u] = beta[u][i+1] +\\\n",
    "                           feature_dict[f\"transition:{ALL_TAGS[v]}+{ALL_TAGS[u]}\"] +\\\n",
    "                           feature_dict[f\"emission:{ALL_TAGS[u]}+{sent[i+1]}\"]\n",
    "                \n",
    "            beta[v][i] = log_sum_exp(temp)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54d6dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(feature_dict, x, y):\n",
    "    score = 0\n",
    "    score += feature_dict[f\"transition:START+{y[0]}\"]\n",
    "    \n",
    "    if f\"emission:{y[0]}+{x[0]}\" in feature_dict:\n",
    "        score += feature_dict[f\"emission:{y[0]}+{x[0]}\"]\n",
    "    \n",
    "    for i in range(1, len(x)):\n",
    "        score += feature_dict[f\"transition:{y[i-1]}+{y[i]}\"]\n",
    "        \n",
    "        if f\"emission:{y[i]}+{x[i]}\" in feature_dict:\n",
    "            score += feature_dict[f\"emission:{y[i]}+{x[i]}\"]\n",
    "\n",
    "    score += feature_dict[f\"transition:{y[-1]}+STOP\"]\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b46a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46.66025618822654"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(feature_dict,\n",
    "              'Great food with an awesome atmosphere !'.split(),\n",
    "              'O B-positive O O O B-positive O'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dcfb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X_train, y_train, feature_dict):\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        gold_score = compute_score(feature_dict, X_train[i], y_train[i])\n",
    "        _, total_score = forward(X_train[i], feature_dict)\n",
    "        loss += gold_score - total_score\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b07d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss with features from part 1: 2050.740533835358\n"
     ]
    }
   ],
   "source": [
    "temp_loss = compute_loss(x_train, y_train, feature_dict)\n",
    "print('Loss with features from part 1:', temp_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec66b4",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a15b43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_soft_count(sent, feature_dict, alpha, beta, score):\n",
    "    result = defaultdict(int)\n",
    "    for k in feature_dict:\n",
    "        result[k] = 0\n",
    "    \n",
    "    # transition\n",
    "    for i in range(all_tags_len):\n",
    "        update = alpha[i][0] + beta[i][0] - score\n",
    "        result[f\"transition:START+{ALL_TAGS[i]}\"] += np.exp(update)\n",
    "    \n",
    "    for i in range(1, len(sent)):\n",
    "        for u in range(all_tags_len):\n",
    "            for v in range(all_tags_len):\n",
    "                string = f\"transition:{ALL_TAGS[v]}+{ALL_TAGS[u]}\"\n",
    "                update = alpha[v][i-1] \\\n",
    "                                + feature_dict[string] \\\n",
    "                                + feature_dict[f\"emission:{ALL_TAGS[u]}+{sent[i]}\"] \\\n",
    "                                + beta[u][i] - score\n",
    "                result[string] += np.exp(update)\n",
    "\n",
    "    for i in range(all_tags_len):\n",
    "        update = alpha[i][-1] + beta[i][-1] - score\n",
    "        result[f\"transition:{ALL_TAGS[i]}+STOP\"] += np.exp(update)\n",
    "    \n",
    "    # emission\n",
    "    for i in range(len(sent)):\n",
    "        for j in range(all_tags_len):\n",
    "            string = f\"emission:{ALL_TAGS[j]}+{sent[i]}\"\n",
    "            update = alpha[j][i] + beta[j][i] - score\n",
    "            result[string] += np.exp(update)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfaa9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hard_count(x, y, feature_dict):\n",
    "    result = defaultdict(int)\n",
    "    for k in feature_dict:\n",
    "        result[k] = 0\n",
    "    \n",
    "    # start\n",
    "    result[f\"transition:START+{y[0]}\"] += 1\n",
    "    result[f\"emission:{y[0]}+{x[0]}\"] += 1\n",
    "    \n",
    "    # recursive\n",
    "    for i in range(1, len(x)):\n",
    "        result[f\"transition:+{y[i-1]}+{y[i]}\"] += 1\n",
    "        result[f\"emission:{y[i]}+{x[i]}\"] += 1\n",
    "    \n",
    "    # end\n",
    "    result[f\"transition:{y[-1]}+STOP\"] += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20cc39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_grad(x, y, feature_dict):\n",
    "    grad_dict = defaultdict(int)\n",
    "    for k in feature_dict:\n",
    "        grad_dict[k] = 0\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        alpha, forward_score = forward(x[i], feature_dict)\n",
    "        beta = backward(x[i], feature_dict)\n",
    "        \n",
    "        # loss\n",
    "        expected_result = compute_score(feature_dict, x[i], y[i])\n",
    "        loss += expected_result - forward_score\n",
    "        \n",
    "        # gradient\n",
    "        soft_dict = compute_soft_count(x[i], feature_dict, alpha, beta, forward_score)\n",
    "        hard_dict = compute_hard_count(x[i], y[i], feature_dict)\n",
    "        for feat in feature_dict:\n",
    "            update = soft_dict[feat] - hard_dict[feat]\n",
    "            grad_dict[feat] += update\n",
    "    \n",
    "    return -loss, grad_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2da0b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_index_mapping(feat_dict):\n",
    "    feat_mapping = {}\n",
    "    index_mapping = {}\n",
    "    index = 0\n",
    "    \n",
    "    for key in feat_dict:\n",
    "        feat_mapping[key] = index\n",
    "        index_mapping[index] = key\n",
    "        index += 1\n",
    "        \n",
    "    return feat_mapping, index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ac7c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h:.0f}h {m:.0f}m {s:.2f}s\"\n",
    "\n",
    "def now():\n",
    "    tz = pytz.timezone('Asia/Singapore')\n",
    "    now = datetime.now(tz)\n",
    "    return datetime.strftime(now, \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e5a84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_grad(w, *args):\n",
    "    '''\n",
    "    This function will be called by \"fmin_l_bfgs_b\"\n",
    "    Arg:\n",
    "    w: weights, numpy array\n",
    "    Returns:\n",
    "    loss: loss, float\n",
    "    grads: gradients, numpy array\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    grads = np.zeros(len(w))\n",
    "    x, y  = args\n",
    "    \n",
    "    features_dict = {}\n",
    "    for i in range(len(w)):\n",
    "        features_dict[index_mapping[i]] = w[i]\n",
    "        \n",
    "    loss, grad_dict = compute_loss_and_grad(x, y, features_dict)\n",
    "    \n",
    "    # loss with reg\n",
    "    loss += LEARN_CO * np.sum(w**2)\n",
    "    \n",
    "    # grad with reg\n",
    "    for key in grad_dict:\n",
    "        grads[feat_mapping[key]] = grad_dict[key] + 2 * LEARN_CO * w[feat_mapping[key]]\n",
    "    \n",
    "    \n",
    "    print(f\"Now:\\t\\t{now()}\")\n",
    "    print(f\"loss:\\t\\t{loss:.5f}\")\n",
    "    print(f\"time taken for computing loss:\\t{format_time(time.time() - start_time)}\")\n",
    "    print(f\"overall time taken so far:\\t{format_time(time.time() - OVERALL_START)}\")\n",
    "    print(\"\\n\")\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b50408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Start training CRF--------------------\n",
      "Now:\t\t2022-08-04 18:53:40\n",
      "loss:\t\t52775.02915\n",
      "time taken for computing loss:\t0h 1m 9.84s\n",
      "overall time taken so far:\t0h 1m 9.88s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 18:54:48\n",
      "loss:\t\t50475.71643\n",
      "time taken for computing loss:\t0h 1m 7.84s\n",
      "overall time taken so far:\t0h 2m 17.76s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 18:55:38\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 50.49s\n",
      "overall time taken so far:\t0h 3m 8.25s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 18:56:29\n",
      "loss:\t\t83922.04478\n",
      "time taken for computing loss:\t0h 0m 50.58s\n",
      "overall time taken so far:\t0h 3m 58.84s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 18:57:20\n",
      "loss:\t\t48151.10457\n",
      "time taken for computing loss:\t0h 0m 50.80s\n",
      "overall time taken so far:\t0h 4m 49.64s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 18:58:10\n",
      "loss:\t\t44214.49633\n",
      "time taken for computing loss:\t0h 0m 50.66s\n",
      "overall time taken so far:\t0h 5m 40.31s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 18:59:01\n",
      "loss:\t\t43670.59073\n",
      "time taken for computing loss:\t0h 0m 50.63s\n",
      "overall time taken so far:\t0h 6m 30.94s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 18:59:51\n",
      "loss:\t\t43580.41045\n",
      "time taken for computing loss:\t0h 0m 50.03s\n",
      "overall time taken so far:\t0h 7m 20.97s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:00:42\n",
      "loss:\t\t43564.80008\n",
      "time taken for computing loss:\t0h 0m 50.81s\n",
      "overall time taken so far:\t0h 8m 11.78s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:01:32\n",
      "loss:\t\t43562.07635\n",
      "time taken for computing loss:\t0h 0m 50.27s\n",
      "overall time taken so far:\t0h 9m 2.05s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:02:22\n",
      "loss:\t\t43561.60044\n",
      "time taken for computing loss:\t0h 0m 49.99s\n",
      "overall time taken so far:\t0h 9m 52.05s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:03:12\n",
      "loss:\t\t43561.51727\n",
      "time taken for computing loss:\t0h 0m 49.96s\n",
      "overall time taken so far:\t0h 10m 42.01s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:04:02\n",
      "loss:\t\t43561.50273\n",
      "time taken for computing loss:\t0h 0m 49.88s\n",
      "overall time taken so far:\t0h 11m 31.89s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:04:51\n",
      "loss:\t\t43561.50019\n",
      "time taken for computing loss:\t0h 0m 49.58s\n",
      "overall time taken so far:\t0h 12m 21.47s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:05:41\n",
      "loss:\t\t43561.49974\n",
      "time taken for computing loss:\t0h 0m 49.82s\n",
      "overall time taken so far:\t0h 13m 11.29s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:06:31\n",
      "loss:\t\t43561.49967\n",
      "time taken for computing loss:\t0h 0m 49.65s\n",
      "overall time taken so far:\t0h 14m 0.94s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:07:21\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 49.78s\n",
      "overall time taken so far:\t0h 14m 50.73s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:08:10\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 49.63s\n",
      "overall time taken so far:\t0h 15m 40.36s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:09:00\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 49.68s\n",
      "overall time taken so far:\t0h 16m 30.04s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:09:50\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 49.79s\n",
      "overall time taken so far:\t0h 17m 19.83s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:10:40\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 49.72s\n",
      "overall time taken so far:\t0h 18m 9.55s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:11:29\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 49.80s\n",
      "overall time taken so far:\t0h 18m 59.35s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:12:19\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 49.66s\n",
      "overall time taken so far:\t0h 19m 49.02s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:13:09\n",
      "loss:\t\t11402255.71348\n",
      "time taken for computing loss:\t0h 0m 49.71s\n",
      "overall time taken so far:\t0h 20m 38.73s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:13:59\n",
      "loss:\t\t1260750.25095\n",
      "time taken for computing loss:\t0h 0m 49.76s\n",
      "overall time taken so far:\t0h 21m 28.50s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:14:49\n",
      "loss:\t\t190511.74846\n",
      "time taken for computing loss:\t0h 0m 50.39s\n",
      "overall time taken so far:\t0h 22m 18.89s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:15:39\n",
      "loss:\t\t60010.61025\n",
      "time taken for computing loss:\t0h 0m 50.26s\n",
      "overall time taken so far:\t0h 23m 9.15s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:16:29\n",
      "loss:\t\t45626.10944\n",
      "time taken for computing loss:\t0h 0m 50.17s\n",
      "overall time taken so far:\t0h 23m 59.32s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:17:20\n",
      "loss:\t\t43846.87634\n",
      "time taken for computing loss:\t0h 0m 50.28s\n",
      "overall time taken so far:\t0h 24m 49.61s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:18:10\n",
      "loss:\t\t43601.65436\n",
      "time taken for computing loss:\t0h 0m 50.15s\n",
      "overall time taken so far:\t0h 25m 39.76s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:19:02\n",
      "loss:\t\t43567.16448\n",
      "time taken for computing loss:\t0h 0m 51.78s\n",
      "overall time taken so far:\t0h 26m 31.54s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:19:52\n",
      "loss:\t\t43562.29911\n",
      "time taken for computing loss:\t0h 0m 50.25s\n",
      "overall time taken so far:\t0h 27m 21.79s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:20:42\n",
      "loss:\t\t43561.61248\n",
      "time taken for computing loss:\t0h 0m 50.11s\n",
      "overall time taken so far:\t0h 28m 11.91s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:21:32\n",
      "loss:\t\t43561.51557\n",
      "time taken for computing loss:\t0h 0m 50.13s\n",
      "overall time taken so far:\t0h 29m 2.04s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:22:22\n",
      "loss:\t\t43561.50190\n",
      "time taken for computing loss:\t0h 0m 50.27s\n",
      "overall time taken so far:\t0h 29m 52.31s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:23:12\n",
      "loss:\t\t43561.49997\n",
      "time taken for computing loss:\t0h 0m 50.10s\n",
      "overall time taken so far:\t0h 30m 42.41s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:24:03\n",
      "loss:\t\t43561.49969\n",
      "time taken for computing loss:\t0h 0m 50.26s\n",
      "overall time taken so far:\t0h 31m 32.67s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:24:53\n",
      "loss:\t\t43561.49966\n",
      "time taken for computing loss:\t0h 0m 50.09s\n",
      "overall time taken so far:\t0h 32m 22.76s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:25:43\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 50.72s\n",
      "overall time taken so far:\t0h 33m 13.48s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:26:34\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 50.13s\n",
      "overall time taken so far:\t0h 34m 3.61s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:27:24\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 50.22s\n",
      "overall time taken so far:\t0h 34m 53.83s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:28:14\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 50.12s\n",
      "overall time taken so far:\t0h 35m 43.95s\n",
      "\n",
      "\n",
      "Now:\t\t2022-08-04 19:29:04\n",
      "loss:\t\t43561.49965\n",
      "time taken for computing loss:\t0h 0m 50.02s\n",
      "overall time taken so far:\t0h 36m 33.97s\n",
      "\n",
      "\n",
      "final loss:\t\t43561.499649778125\n",
      "--------------------Training finished--------------------\n",
      "TOTAL TIME TAKEN: 0h 36m 33.98s\n"
     ]
    }
   ],
   "source": [
    "feat_mapping, index_mapping = feat_index_mapping(feature_dict)\n",
    "\n",
    "print(\"-\"*20 + \"Start training CRF\" + \"-\"*20)\n",
    "OVERALL_START = time.time()\n",
    "\n",
    "opt_w, final_loss, _ = fmin_l_bfgs_b(get_loss_grad,\n",
    "                 x0 = np.zeros(len(index_mapping)), #initial weight guess\n",
    "                 pgtol = 0.01,\n",
    "                 args = (x_train, y_train))\n",
    "\n",
    "print(f\"final loss:\\t\\t{final_loss}\")\n",
    "\n",
    "print(\"-\"*20 + 'Training finished' + \"-\"*20)\n",
    "\n",
    "TT = time.time() - OVERALL_START\n",
    "print(f\"TOTAL TIME TAKEN: {format_time(TT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12bf375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_feat = {}\n",
    "for i in range(len(opt_w)):\n",
    "    pred_feat[index_mapping[i]] = opt_w[i]\n",
    "\n",
    "x_dev = read_validation_file(DATA_FILE + '/dev.in')\n",
    "y_dev = []\n",
    "\n",
    "for i in range(len(x_dev)):\n",
    "    output, _ = viterbi(x_dev[i], pred_feat)\n",
    "    y_dev.append(output[1:-1])\n",
    "\n",
    "write_output(DATA_FILE + '/dev.p4.out', x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf771d3",
   "metadata": {},
   "source": [
    "# Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5007808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b1db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"dataset\" # dir where your train/dev.in is stored\n",
    "FEATURE_OUTPUT_DIRECTORY = \"features\"\n",
    "LEARN_CO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e62f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_file(directory):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    all_tags = []\n",
    "    all_words = []\n",
    "\n",
    "    with open(directory) as f:\n",
    "        x_sent = []\n",
    "        y = []\n",
    "        for line in f:\n",
    "            if line == '\\n': # end of a sentence\n",
    "                x_train.append(x_sent)\n",
    "                y_train.append(y)\n",
    "                x_sent=[]\n",
    "                y=[]\n",
    "            else:\n",
    "                temp = line.strip().split()\n",
    "                x_sent.append(temp[0]) # word\n",
    "                y.append(temp[1]) # tag\n",
    "\n",
    "                if temp[1] not in all_tags:\n",
    "                    all_tags.append(temp[1])\n",
    "                if temp[0] not in all_words:\n",
    "                    all_words.append(temp[0])\n",
    "\n",
    "    return x_train, y_train, all_tags, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10b9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, ALL_TAGS,  ALL_WORDS = read_train_file(DATA_FILE + '/train')\n",
    "all_tags_len = len(ALL_TAGS)\n",
    "# x_train\n",
    "# ALL_TAGS # without START, STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b1a81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_feature(feat, output_file):\n",
    "    with open(output_file, \"w\") as out:\n",
    "        for (k, v) in feat.items():\n",
    "            out.write(f\"{k} {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c67c3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict_part5(x_train, y_train, output_dir):\n",
    "    \n",
    "    features = {}\n",
    "    tags = ALL_TAGS + [\"START\", \"STOP\"]\n",
    "    \n",
    "    #Initiate transition\n",
    "    for i in tags:\n",
    "        for j in tags:\n",
    "            for e in ALL_WORDS:\n",
    "                string = f\"transition:{str(i)}+{str(j)}+{str(e)}\"\n",
    "                features[string] = -2**21\n",
    "    \n",
    "    #Initiate emission dictionaries 1 and 2\n",
    "    for j in ALL_TAGS:\n",
    "        for i in ALL_WORDS:\n",
    "            string = f\"emission1:{str(j)}+{str(i)}\"\n",
    "            features[string] = -2**21\n",
    "\n",
    "    for j in ALL_TAGS:\n",
    "        for i in ALL_WORDS:\n",
    "            string = f\"emission2:{str(j)}+{str(i)}\"\n",
    "            features[string] = -2**21\n",
    "    \n",
    "    #Initiate dictionary for counting emissions\n",
    "    label_dict = defaultdict(int)  # {LABEL : COUNT} e.g: {'o': 24273, 'B-negative': 278, ...}\n",
    "    word_label_dict_prev = defaultdict(int) # {(LABEL, WORD): COUNT} \n",
    "                               # e.g: {('O', 'All'): 3, ('B-positive', 'food'): 131, ...}\n",
    "    word_label_dict_next = defaultdict(int) \n",
    "\n",
    "    #Populate dictionary for emission 1 with count\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(1,len(x_train[i])):\n",
    "            label_dict[y_train[i][j]] += 1\n",
    "            word_label_dict_prev[(y_train[i][j], x_train[i][j-1])] += 1\n",
    "\n",
    "    #Populate dictionary for emission 2 with count\n",
    "    for i in range(len(x_train)):\n",
    "        for j in range(len(x_train[i])-1):\n",
    "            label_dict[y_train[i][j]] += 1\n",
    "            word_label_dict_next[(y_train[i][j], x_train[i][j+1])] += 1\n",
    "    \n",
    "    # print(f\"y_dict: {y_dict}\")\n",
    "    # print(f\"yx_dict: {yx_dict}\")\n",
    "\n",
    "    #Populate dictionary of emission 1 with log prob\n",
    "    emission_prev = defaultdict(int)\n",
    "    for k in word_label_dict_prev:\n",
    "        tag = k[0]\n",
    "        string = f\"emission1:{str(k[0])}+{str(k[1])}\"\n",
    "        emission_prev[string] = math.log(float(word_label_dict_prev[k])/label_dict[tag])\n",
    "    # print(f\"emission: {emission}\")\n",
    "\n",
    "    #Populate dictionary of emission 2 with log prob\n",
    "    emission_next = defaultdict(int)\n",
    "    for k in word_label_dict_next:\n",
    "        tag = k[0]\n",
    "        string = f\"emission:{str(k[0])}+{str(k[1])}\"\n",
    "        emission_next[string] = math.log(float(word_label_dict_next[k])/label_dict[tag])\n",
    "\n",
    "    # getting transition\n",
    "    yi_dict = defaultdict(int)\n",
    "    yj_dict = defaultdict(int)\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "#         if len(y_train[i]) == 0: # this seems to be useless\n",
    "#             continue\n",
    "\n",
    "         # adding START and STOP tag to each sentence\n",
    "        yi_dict['START'] += 1\n",
    "        yj_dict[('START', y_train[i][0],x_train[i][0])] += 1\n",
    "        yj_dict[(y_train[i][-1],'STOP',None)] += 1\n",
    "\n",
    "        for j in range(1,len(x_train[i])):\n",
    "            yi_dict[y_train[i][j]] += 1\n",
    "            yj_dict[(y_train[i][j-1],y_train[i][j],x_train[i][j])] += 1\n",
    "        # yi_dict[y_train[i][-1]] += 1\n",
    "                \n",
    "    transition = defaultdict(int)\n",
    "    for k in yj_dict:\n",
    "        string = f\"transition:{str(k[0])}+{str(k[1])}+{str(k[2])}\"\n",
    "        transition[string] = math.log(float(yj_dict[k])/yi_dict[k[0]])\n",
    "    \n",
    "    # if \"transition:START+STOP\" in transition:\n",
    "    #     del transition[\"transition:START+STOP\"]\n",
    "\n",
    "    write_feature(emission_prev, output_dir + \"/emission_P5_1.txt\") # save emission 1 dictionary\n",
    "    write_feature(emission_next, output_dir + \"/emission_P5_2.txt\") # save emission 2 dictionary\n",
    "    write_feature(transition, output_dir + \"/transition_P5.txt\") # save transition dictionary\n",
    "\n",
    "    for key in emission_prev:\n",
    "        features[key] = emission_prev[key]\n",
    "    for key in emission_next:\n",
    "        features[key] = emission_next[key]\n",
    "    for key in transition:\n",
    "        features[key] = transition[key]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b560f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = get_feature_dict_part5(x_train, y_train, FEATURE_OUTPUT_DIRECTORY)\n",
    "write_feature(feature_dict, FEATURE_OUTPUT_DIRECTORY + \"/features_P5.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "22506509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_part5(sent, feature_dict): \n",
    "    table = []\n",
    "    for i in range(all_tags_len):\n",
    "        temp = []\n",
    "        for j in range(len(sent)):\n",
    "            temp.append(-2**31)\n",
    "        table.append(temp)\n",
    "            \n",
    "    trace = []\n",
    "    for j in range(all_tags_len):\n",
    "        temp = []\n",
    "        for i in range(len(sent)):\n",
    "            temp.append(None)\n",
    "        trace.append(temp)\n",
    "    \n",
    "    score = -2**31\n",
    "    pointer = None\n",
    "    \n",
    "    # START -> first tag\n",
    "    # check first word sent[0]\n",
    "    for i in range(all_tags_len):\n",
    "        trace[i][0] = 'START'\n",
    "        if (f\"emission2:{ALL_TAGS[i]}+{sent[1]}\" in feature_dict):\n",
    "            table[i][0] = feature_dict[f\"transition:START+{ALL_TAGS[i]}+{sent[0]}\"] +\\\n",
    "                          feature_dict[f\"emission2:{ALL_TAGS[i]}+{sent[1]}\"]\n",
    "        else:\n",
    "            table[i][0] = feature_dict[f\"transition:START+{ALL_TAGS[i]}+{sent[0]}\"]\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    # iterate through the rest of sent\n",
    "    for s in range(1, len(sent)):\n",
    "        for v in range(all_tags_len):\n",
    "            \n",
    "            # transition score u -> v\n",
    "            for u in range(all_tags_len):\n",
    "                if table[v][s] < table[u][s-1] + feature_dict[f\"transition:{ALL_TAGS[u]}+{ALL_TAGS[v]}+{sent[s]}\"]:\n",
    "                    table[v][s] = table[u][s-1] + feature_dict[f\"transition:{ALL_TAGS[u]}+{ALL_TAGS[v]}+{sent[s]}\"]\n",
    "                    trace[v][s] = u\n",
    "                    \n",
    "            if (f\"emission:{ALL_TAGS[v]}+{sent[s]}\" in feature_dict):\n",
    "                if s!=len(sent)-1:\n",
    "                    table[v][s] += feature_dict[f\"emission2:{ALL_TAGS[v]}+{sent[s+1]}\"] + feature_dict[f\"emission1:{ALL_TAGS[v]}+{sent[s-1]}\"]\n",
    "                else:\n",
    "                    table[v][s] += feature_dict[f\"emission1:{ALL_TAGS[v]}+{sent[s-1]}\"]\n",
    "        \n",
    "\n",
    "                \n",
    "    # last word -> STOP\n",
    "    for i in range(all_tags_len):\n",
    "        # print(\"Best Score: \"+ str(score))\n",
    "        # print(\"Prev score: \"+str(table[i][-2]))\n",
    "        # print(\"Current score: \"+str(feature_dict[f\"transition:{ALL_TAGS[i]}+STOP+{sent[-1]}\"]))\n",
    "        if score < table[i][-1] + feature_dict[f\"transition:{ALL_TAGS[i]}+STOP+{None}\"]:\n",
    "            score = table[i][-1] + feature_dict[f\"transition:{ALL_TAGS[i]}+STOP+{None}\"]\n",
    "            pointer = i\n",
    "    \n",
    "    output = ['STOP']\n",
    "    output.append(ALL_TAGS[pointer])\n",
    "    wanted_tag = pointer\n",
    "\n",
    "    for i in range(len(sent)-1, 0, -1):\n",
    "        output.append(ALL_TAGS[trace[wanted_tag][i]])\n",
    "        wanted_tag = trace[wanted_tag][i]\n",
    "    \n",
    "    output.append('START')\n",
    "    return output[::-1], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6879b9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['START', 'O', 'I-negative', 'O', 'O', 'O', 'B-negative', 'O', 'STOP'],\n",
       " -10485826.33074927)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_part5('Great food with an awesome atmosphere !'.split(), feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = read_validation_file(DATA_FILE +'/dev.in')\n",
    "y_dev = []\n",
    "\n",
    "for i in range(len(x_dev)):\n",
    "    output,_ = viterbi(x_dev[i], feature_dict)\n",
    "    y_dev.append(output[1:-1]) #remove START, STOP\n",
    "\n",
    "write_output(DATA_FILE +'/dev.p5.out', x_dev, y_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcf211192b8305e65baef152b0c6fa0a02f332f050fb0f887b1262c425357821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
