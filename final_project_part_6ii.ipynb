{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jFl4qIiUioJ9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "d4dgyU7BjW-4",
    "outputId": "d670224f-8ae2-4043-e23e-1b841c34c453"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# directory = r\"drive/MyDrive/50.040 NLP/final project/dataset\"\n",
    "directory = r\"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uN5b0NOmkg5z"
   },
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBED_DIM = 5\n",
    "HIDDEN_DIM = 4\n",
    "LR = 1e-2\n",
    "DECAY = 1e-4\n",
    "EPOCHS = 150 # 100 epochs took abt 2 hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WdqvqY2qkkWD"
   },
   "outputs": [],
   "source": [
    "def read_train_file(directory):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    all_tags = []\n",
    "    all_words = []\n",
    "    train_data = []\n",
    "\n",
    "    with open(directory) as f:\n",
    "        x_sent = []\n",
    "        y = []\n",
    "        for line in f:\n",
    "            if line == '\\n': # end of a sentence\n",
    "                x_train.append(x_sent)\n",
    "                y_train.append(y)\n",
    "                x_sent = []\n",
    "                y = []\n",
    "            else:\n",
    "                temp = line.strip().split()\n",
    "                x_sent.append(temp[0]) # word\n",
    "                y.append(temp[1]) # tag\n",
    "\n",
    "                if temp[1] not in all_tags:\n",
    "                    all_tags.append(temp[1])\n",
    "                if temp[0] not in all_words:\n",
    "                    all_words.append(temp[0])\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "        train_data.append((x_train[i], y_train[i]))\n",
    "\n",
    "    return train_data, x_train, y_train, all_tags, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FZ7Qpn_fkmMt"
   },
   "outputs": [],
   "source": [
    "def read_validation_file(directory):\n",
    "    dev = []\n",
    "    with open(directory) as f:\n",
    "        s = []\n",
    "        for line in f:\n",
    "            if line == \"\\n\":\n",
    "                if len(s) == 0: # there are two consecutive blank spaces\n",
    "                    continue\n",
    "                else:\n",
    "                    dev.append(s)\n",
    "                    s = []\n",
    "            else:\n",
    "                temp = line.strip()\n",
    "                s.append(temp)\n",
    "    return dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_index_mapping(data):\n",
    "    index_mapping = {'UNK':0}\n",
    "    for sent, _ in data:\n",
    "        for w in sent:\n",
    "            if w not in index_mapping:\n",
    "                index_mapping[w] = len(index_mapping)\n",
    "    \n",
    "    return index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_index_mapping(data):\n",
    "    tag_mapping = {}\n",
    "    for label in data:\n",
    "        if label not in tag_mapping:\n",
    "            tag_mapping[label] = len(tag_mapping)\n",
    "            \n",
    "    tag_mapping[START_TAG] = len(tag_mapping)\n",
    "    tag_mapping[STOP_TAG] = len(tag_mapping)\n",
    "    return tag_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4sbdXWntpUQD"
   },
   "outputs": [],
   "source": [
    "train_data, x_train, y_train, TAGS, _ = read_train_file(directory + '/train')\n",
    "index_mapping = word_index_mapping(train_data)\n",
    "tag_mapping = tag_index_mapping(TAGS)\n",
    "# print(TAGS)\n",
    "# print(tag_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q6X_Z_uVlPkC"
   },
   "outputs": [],
   "source": [
    "def write_output(directory, x, y):\n",
    "    with open(directory, 'w') as f:\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x[i])):\n",
    "                f.write(f\"{x[i][j]} {y[i][j]}\\n\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_write_output(inp_dir, out_dir, model, index_mapping):\n",
    "    x = []\n",
    "    test_file = read_validation_file(inp_dir)\n",
    "    \n",
    "    for i in range(len(test_file)):\n",
    "        x.append(process_input(test_file[i], index_mapping))\n",
    "    \n",
    "    predict = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(x)):\n",
    "            predict.append(model(x[i])[1])\n",
    "            \n",
    "    for i in range(len(predict)):\n",
    "        for j in range(len(predict[i])):\n",
    "            predict[i][j] = TAGS[predict[i][j]]\n",
    "    \n",
    "    write_output(out_dir, x, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MJUnmZUHkCk5"
   },
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    return vec.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QqW4k39XkULm"
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(vec):\n",
    "    _max = vec[0, argmax(vec)]\n",
    "    _max_vec = _max.view(1, -1).expand(1, vec.size()[1])\n",
    "    return _max + torch.log(torch.sum(torch.exp(vec - _max_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YqPozec4kWNu"
   },
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_mapping, embed_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.target_size = len(tag_mapping)\n",
    "        self.tag_mapping = tag_mapping\n",
    "        self.hidden = (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                       torch.randn(2, 1, self.hidden_dim // 2))\n",
    "        \n",
    "        self.word_embedding = nn.Embedding(vocab_size, self.embed_dim)\n",
    "        self.bilstm = nn.LSTM(self.embed_dim, self.hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        self.hidden_to_tag = nn.Linear(hidden_dim, self.target_size)\n",
    "\n",
    "        # transition params\n",
    "        self.transitions = nn.Parameter(torch.randn(self.target_size, self.target_size))\n",
    "\n",
    "        # To prevent transition to START and from STOP\n",
    "        self.transitions.data[tag_mapping[START_TAG], :] = -9999\n",
    "        self.transitions.data[:, tag_mapping[STOP_TAG]] = -9999\n",
    "\n",
    "    def _get_forward_score(self, feature):\n",
    "        alpha = torch.full((1, self.target_size), -10000.)\n",
    "        \n",
    "        # init START_TAG score\n",
    "        alpha[0][self.tag_mapping[START_TAG]] = 0.\n",
    "        placeholder = alpha\n",
    "\n",
    "        for f in feature:\n",
    "            forward_t = [] \n",
    "            for v in range(self.target_size):\n",
    "                emit_score = f[v].view(1, -1)\n",
    "                emit_score = emit_score.expand(1, self.target_size)\n",
    "\n",
    "                # transition of i -> next label\n",
    "                trans_score = self.transitions[v].view(1, -1)\n",
    "                \n",
    "                next_label = placeholder + trans_score + emit_score\n",
    "                # total score\n",
    "                total_score = log_sum_exp(next_label).view(1)\n",
    "                forward_t.append(total_score)\n",
    "            placeholder = torch.cat(forward_t).view(1, -1)\n",
    "\n",
    "        result = placeholder + self.transitions[self.tag_mapping[STOP_TAG]]\n",
    "        return log_sum_exp(result)\n",
    "\n",
    "    def _get_features(self, sent):\n",
    "        # reset\n",
    "        sent_length = len(sent)\n",
    "        self.hidden = (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                       torch.randn(2, 1, self.hidden_dim // 2))\n",
    "        \n",
    "        embeds = self.word_embedding(sent).view(sent_length, 1, -1)\n",
    "        out, self.hidden = self.bilstm(embeds, self.hidden)\n",
    "        feature = self.hidden_to_tag(out.view(sent_length, self.hidden_dim))\n",
    "        return feature\n",
    "\n",
    "    def _get_gold_score(self, feature, labels):\n",
    "        # return the score of the actual tag seq\n",
    "        score = torch.zeros(1)\n",
    "        temp_t = torch.tensor([self.tag_mapping[START_TAG]], dtype=torch.long)\n",
    "        labels = torch.cat([temp_t, labels])\n",
    "        for idx, f in enumerate(feature):\n",
    "            score += self.transitions[labels[idx + 1], labels[idx]] + f[labels[idx + 1]]\n",
    "        score += self.transitions[self.tag_mapping[STOP_TAG], labels[-1]]\n",
    "        return score\n",
    "\n",
    "    def _decode(self, feature):\n",
    "        pointer = []\n",
    "\n",
    "        beta = torch.full((1, self.target_size), -10000.)\n",
    "        beta[0][self.tag_mapping[START_TAG]] = 0\n",
    "        \n",
    "        placeholder = beta\n",
    "\n",
    "        for f in feature:\n",
    "            temp_pointer = []\n",
    "            temp = []\n",
    "            \n",
    "            # transition\n",
    "            for label in range(self.target_size):\n",
    "                # next_label[i] -> label i from the previous step + score of transition(label i -> next label)\n",
    "                next_label = placeholder + self.transitions[label]\n",
    "                best_label = argmax(next_label)\n",
    "\n",
    "                temp_pointer.append(best_label)\n",
    "                temp.append(next_label[0][best_label].view(1))\n",
    "            \n",
    "            # emission score\n",
    "            _temp = torch.cat(temp) + f\n",
    "            placeholder = _temp.view(1, -1)\n",
    "            pointer.append(temp_pointer)\n",
    "\n",
    "        # v -> STOP\n",
    "        terminal = placeholder + self.transitions[self.tag_mapping[STOP_TAG]]\n",
    "        best_label = argmax(terminal)\n",
    "        best_path_score = terminal[0][best_label]\n",
    "\n",
    "        # trace back best path\n",
    "        best_tag_seq = [best_label]\n",
    "        for bp in reversed(pointer):\n",
    "            best_label = bp[best_label]\n",
    "            best_tag_seq.append(best_label)\n",
    "        \n",
    "        # remove start tag\n",
    "        best_tag_seq = best_tag_seq[:-1]\n",
    "        best_tag_seq.reverse()\n",
    "        \n",
    "        return best_path_score, best_tag_seq\n",
    "\n",
    "    def nll_loss(self, sent, tags):\n",
    "        features = self._get_features(sent)\n",
    "        forward = self._get_forward_score(features)\n",
    "        target_score = self._get_gold_score(features, tags)\n",
    "        loss = forward - target_score\n",
    "        return loss\n",
    "\n",
    "    def forward(self, sent):\n",
    "        features = self._get_features(sent)\n",
    "        score, label_seq = self._decode(features)\n",
    "        return score, label_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h:.0f}h {m:.0f}m {s:.2f}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ygEw-ecFkSno"
   },
   "outputs": [],
   "source": [
    "def process_input(sent, index_mapping):\n",
    "    inp = []\n",
    "    for i in range(len(sent)):\n",
    "        try:\n",
    "            inp.append(index_mapping[sent[i]])\n",
    "        except KeyError:\n",
    "            inp.append(index_mapping['UNK'])\n",
    "    \n",
    "    return torch.tensor(inp, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "W8_ABpGlk6OP"
   },
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(len(index_mapping), tag_mapping, EMBED_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_X3-Fesck8QP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t\t\t0\n",
      "loss:\t\t\t0.2519407210582644\n",
      "time taken so far:\t0h 1m 10.44s\n",
      "Epoch:\t\t\t10\n",
      "loss:\t\t\t0.0697127307179113\n",
      "time taken so far:\t0h 12m 53.15s\n",
      "Epoch:\t\t\t20\n",
      "loss:\t\t\t0.06254346862724892\n",
      "time taken so far:\t0h 24m 38.17s\n",
      "Epoch:\t\t\t30\n",
      "loss:\t\t\t0.061056729821626785\n",
      "time taken so far:\t0h 36m 23.55s\n",
      "Epoch:\t\t\t40\n",
      "loss:\t\t\t0.06177653920786302\n",
      "time taken so far:\t0h 48m 8.55s\n",
      "Epoch:\t\t\t50\n",
      "loss:\t\t\t0.0590605245113531\n",
      "time taken so far:\t0h 59m 50.95s\n",
      "Epoch:\t\t\t60\n",
      "loss:\t\t\t0.058663638871194586\n",
      "time taken so far:\t1h 11m 33.25s\n",
      "Epoch:\t\t\t70\n",
      "loss:\t\t\t0.0591599003877714\n",
      "time taken so far:\t1h 23m 15.69s\n",
      "Epoch:\t\t\t80\n",
      "loss:\t\t\t0.05773980858130712\n",
      "time taken so far:\t1h 34m 58.24s\n",
      "Epoch:\t\t\t90\n",
      "loss:\t\t\t0.062226535138081344\n",
      "time taken so far:\t1h 46m 40.00s\n",
      "Epoch:\t\t\t100\n",
      "loss:\t\t\t0.05966374061042671\n",
      "time taken so far:\t1h 58m 11.14s\n",
      "Epoch:\t\t\t110\n",
      "loss:\t\t\t0.05892419811547108\n",
      "time taken so far:\t2h 9m 37.19s\n",
      "Epoch:\t\t\t120\n",
      "loss:\t\t\t0.05752089959735307\n",
      "time taken so far:\t2h 21m 2.81s\n",
      "Epoch:\t\t\t130\n",
      "loss:\t\t\t0.06293952841748354\n",
      "time taken so far:\t2h 32m 26.66s\n",
      "Epoch:\t\t\t140\n",
      "loss:\t\t\t0.05749933814840688\n",
      "time taken so far:\t2h 43m 50.51s\n",
      "total time taken:\t2h 54m 5.34s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS): \n",
    "    loss_num = 0\n",
    "    num = 0\n",
    "    for sent, labels in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        model_input = process_input(sent, index_mapping)\n",
    "        temp = []\n",
    "        for t in labels:\n",
    "            temp.append(tag_mapping[t])\n",
    "        labels = torch.tensor(temp, dtype=torch.long)\n",
    "        \n",
    "        # run model\n",
    "        loss = model.nll_loss(model_input, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_num += loss.item()\n",
    "        num += len(sent)\n",
    "    loss_num /= num\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch:\\t\\t\\t{epoch}\")\n",
    "        print(f\"loss:\\t\\t\\t{loss_num}\")\n",
    "        print(f\"time taken so far:\\t{format_time(time.time() - start_time)}\")\n",
    "print(f\"total time taken:\\t{format_time(time.time()- start_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), directory+\"/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inp_dir = directory + '/dev.in'\n",
    "inp_dir = directory + '/test.in'\n",
    "out_dir = directory + '/test.p6.model.out'\n",
    "predict_and_write_output(inp_dir, out_dir,  model, index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dir = directory + '/dev.in'\n",
    "out_dir = directory + '/model.p6.model.out'\n",
    "predict_and_write_output(inp_dir, out_dir,  model, index_mapping)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
